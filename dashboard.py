import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from st_aggrid import AgGrid, GridOptionsBuilder
from dotenv import load_dotenv
import os
from collections import Counter
from datetime import datetime, timedelta

# --- Session State Initialization ---
if 'page_number' not in st.session_state:
    st.session_state.page_number = 0
if 'current_skill' not in st.session_state:
    st.session_state.current_skill = None


# --- è¼‰å…¥è³‡æ–™ä¸¦é è™•ç† ---
@st.cache_data
def load_data():
    # å¾ Parquet æª”æ¡ˆè®€å–æ•¸æ“šï¼Œè€Œä¸æ˜¯è³‡æ–™åº«
    df = pd.read_parquet("./jobs_data.parquet")

    df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce")

    # è–ªè³‡æ¨™æº–åŒ– (å„ªåŒ–ç‰ˆ)
    def normalize_and_clean_salary(row):
        salary_min = row['salary_min']
        salary_max = row['salary_max']
        salary_type = row['salary_type']

        if pd.isna(salary_min):
            return None

        # æ­¥é©Ÿ 1: å¦‚æœæä¾›æœ‰æ•ˆçš„è–ªè³‡ç¯„åœï¼Œå‰‡ä½¿ç”¨å¹³å‡å€¼
        base_salary = salary_min
        if pd.notna(salary_max) and salary_max > salary_min:
            base_salary = (salary_min + salary_max) / 2

        # æ­¥é©Ÿ 2: æ ¹æ“šè–ªè³‡é¡å‹é€²è¡Œæ¨™æº–åŒ–
        normalized_salary = base_salary
        if salary_type == "å¹´è–ª":
            normalized_salary = base_salary / 12
        elif salary_type == "æ—¥è–ª":
            # å°æ¨™ç¤ºéŒ¯èª¤çš„æ—¥è–ªé€²è¡Œå¥å…¨æ€§æª¢æŸ¥
            if base_salary > 20000:
                normalized_salary = base_salary
            else:
                normalized_salary = base_salary * 22
        elif salary_type == "æ™‚è–ª":
            # å°æ¨™ç¤ºéŒ¯èª¤çš„æ™‚è–ªé€²è¡Œå¥å…¨æ€§æª¢æŸ¥
            if base_salary > 2000:
                normalized_salary = base_salary
            else:
                normalized_salary = base_salary * 176
        
        # æ­¥é©Ÿ 3: å°æ¥µé«˜çš„æœˆè–ªé€²è¡Œæœ€çµ‚å¥å…¨æ€§æª¢æŸ¥ (å¯èƒ½ç‚ºèª¤æ¨™çš„å¹´è–ª)
        if pd.notna(normalized_salary) and normalized_salary > 500000:
            return normalized_salary / 12

        return normalized_salary

    df["monthly_salary"] = df.apply(normalize_and_clean_salary, axis=1)
    
    # ä½¿ç”¨ aggregated_skills è¨ˆç®—æŠ€èƒ½æ•¸é‡
    df["skills_count"] = (
        df["aggregated_skills"].fillna("").apply(lambda x: len(x.split(",")) if x else 0)
    )
    # ç‚ºäº†å¾ŒçºŒåœ–è¡¨ç›¸å®¹æ€§ï¼Œå¦‚æœ aggregated_skills å­˜åœ¨ï¼Œå°±ç”¨å®ƒè¦†è“‹èˆŠçš„ required_skills
    if "aggregated_skills" in df.columns:
        df["required_skills"] = df["aggregated_skills"]
        
    return df


# --- ä¸»ç¨‹å¼é‚è¼¯ ---
st.set_page_config(page_title="å°±æ¥­å¸‚å ´ Dashboard", layout="wide")

# st.title("ğŸ“Š å°±æ¥­å¸‚å ´ç¸½è¦½")

df = load_data()

# Fill missing city data with 'é ç«¯å·¥ä½œ' to prevent them from being filtered out
df['city'] = df['city'].fillna('é ç«¯å·¥ä½œ')

# --- Sidebar Filters ---
st.sidebar.header("ç¯©é¸å™¨")

# --- çµ±ä¸€åŸå¸‚åç¨± ---
city_name_map = {
    'å°åŒ—å¸‚': 'è‡ºåŒ—å¸‚',
    'å°ä¸­å¸‚': 'è‡ºä¸­å¸‚',
    'å°å—å¸‚': 'è‡ºå—å¸‚',
    'å°æ±ç¸£': 'è‡ºæ±ç¸£',
    'æ–°ç«¹å¸‚': 'æ–°ç«¹',
    'æ–°ç«¹ç¸£': 'æ–°ç«¹'
}
df['city'] = df['city'].replace(city_name_map)

selected_platform = st.sidebar.multiselect(
    "å¹³å°",
    options=df["platform"].unique(),
    default=df["platform"].unique(),
)

# å®šç¾©å°ç£åŸå¸‚åˆ—è¡¨ï¼Œç”¨æ–¼éæ¿¾ç¯©é¸å™¨é¸é …
TAIWAN_CITIES = [
    'è‡ºåŒ—å¸‚', 'æ–°åŒ—å¸‚', 'æ¡ƒåœ’å¸‚', 'è‡ºä¸­å¸‚', 'è‡ºå—å¸‚', 'é«˜é›„å¸‚', 'åŸºéš†å¸‚', 'æ–°ç«¹', 'å˜‰ç¾©å¸‚',
    'è‹—æ —ç¸£', 'å½°åŒ–ç¸£', 'å—æŠ•ç¸£', 'é›²æ—ç¸£', 'å˜‰ç¾©ç¸£', 'å±æ±ç¸£', 'å®œè˜­ç¸£', 'èŠ±è“®ç¸£',
    'è‡ºæ±ç¸£', 'æ¾æ¹–ç¸£', 'é‡‘é–€ç¸£', 'é€£æ±Ÿç¸£', 'é ç«¯å·¥ä½œ'
]

# å¾ DataFrame ä¸­å–å¾—æ‰€æœ‰åŸå¸‚ï¼Œä¸¦ç¯©é¸å‡ºå°ç£çš„åŸå¸‚
available_cities = df['city'].dropna().unique()
taiwan_cities_in_df = sorted([city for city in available_cities if city in TAIWAN_CITIES])

selected_city = st.sidebar.multiselect(
    "åŸå¸‚",
    options=taiwan_cities_in_df,
    default=taiwan_cities_in_df,
)

# --- Define categories to exclude from all analyses ---
EXCLUDED_CATEGORIES = [
    'å…¶ä»–è³‡è¨Šå°ˆæ¥­äººå“¡',
    'UI/UXè¨­è¨ˆå¸«',
    'MISå·¥ç¨‹å¸«',
    'MESå·¥ç¨‹å¸«',
    'ç¶²è·¯å®‰å…¨åˆ†æå¸«',
    'ç¶²è·¯ç®¡ç†å·¥ç¨‹å¸«'
]

df_filtered = df[
    df["platform"].isin(selected_platform) &
    df["city"].isin(selected_city) &
    ~df["category_name"].isin(EXCLUDED_CATEGORIES)
]

# --- Globally exclude 'é¢è­°' jobs defaulted to 40k for more accurate analysis ---
df_filtered = df_filtered[~((df_filtered['salary_type'] == 'é¢è­°') & (df_filtered['monthly_salary'] == 40000))]


# Define a global constant for salary filtering
MAX_REASONABLE_SALARY = 200000


# --- KPI Cards ---
col1, col2, col3, col4 = st.columns(4)

# 1. Total Jobs
col1.metric("ğŸ“Œ è·ç¼ºç¸½æ•¸", f"{len(df_filtered):,}")

# 2. Recruiting Companies
num_companies = df_filtered['company_name'].nunique()
col2.metric("ğŸ¢ å¾µæ‰å…¬å¸æ•¸", f"{num_companies:,}")

# 3. Median Salary
salary_df_for_median = df_filtered.dropna(subset=['monthly_salary'])
salary_df_for_median = salary_df_for_median[salary_df_for_median['monthly_salary'] < MAX_REASONABLE_SALARY]
# æ’é™¤è–ªè³‡ç‚º 40000 ä¸”é¡å‹ç‚ºã€Œé¢è­°ã€çš„è·ç¼ºï¼Œä»¥è¨ˆç®—æ›´çœŸå¯¦çš„ä¸­ä½æ•¸
adjusted_salary_df = salary_df_for_median[~((salary_df_for_median['salary_type'] == 'é¢è­°') & (salary_df_for_median['monthly_salary'] == 40000))]
median_salary = adjusted_salary_df['monthly_salary'].median() if not adjusted_salary_df.empty else 0
col3.metric("ğŸ’µ è–ªè³‡ä¸­ä½æ•¸ (æœˆ)", f"{median_salary:,.0f} å…ƒ")

# 4. Median Experience Requirement
exp_df_for_median = df_filtered.copy()
exp_df_for_median['experience_min'] = pd.to_numeric(exp_df_for_median['experience_min'], errors='coerce')
exp_df_for_median = exp_df_for_median.dropna(subset=['experience_min'])
median_exp = exp_df_for_median['experience_min'].median() if not exp_df_for_median.empty else 0
col4.metric("ğŸ“ˆ ç¶“é©—è¦æ±‚ä¸­ä½æ•¸ (å¹´)", f"{median_exp:.1f} å¹´")


st.divider()

# --- Market Overview ---

c1, c2 = st.columns(2)

with c1:
    # 1. Job count per platform (Rebuilt with plotly.graph_objects to fix display bug)
    platform_df = df_filtered.dropna(subset=['platform'])
    platform_df['platform'] = platform_df['platform'].astype(str)
    platform_counts = platform_df["platform"].value_counts().reset_index()
    platform_counts.columns = ["platform", "count"]
    
    fig_platform = go.Figure(data=[go.Bar(
        x=platform_counts['platform'],
        y=platform_counts['count'],
        text=platform_counts['count'],
        textposition='outside',
        texttemplate='%{text:,.0f}'
    )])
    
    fig_platform.update_layout(
        title_text='å„å¹³å°è·ç¼ºæ•¸é‡',
        xaxis_title='å¹³å°',
        yaxis_title='è·ç¼ºæ•¸',
        xaxis={'categoryorder':'total descending'}
    )
    st.plotly_chart(fig_platform, use_container_width=True)

with c2:
    # 2. Job count per city (Top 10)
    city_df = df_filtered["city"].dropna().value_counts().nlargest(10).reset_index()
    city_df.columns = ["city", "count"]
    fig_city = px.bar(
        city_df,
        y="count",
        x="city",
        title="å„åŸå¸‚è·ç¼ºæ•¸é‡ (Top 10)",
        labels={'city': 'åŸå¸‚', 'count': 'è·ç¼ºæ•¸'},
        text='count'
    )
    fig_city.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_city.update_layout(xaxis={'categoryorder':'total descending'})
    st.plotly_chart(fig_city, use_container_width=True)

c3, c4 = st.columns(2)

with c3:
    # Top Paying Categories
    cat_counts = df_filtered['category_name'].value_counts()
    valid_categories = cat_counts[cat_counts >= 5].index
    high_paying_cat_df = df_filtered[df_filtered['category_name'].isin(valid_categories)].copy()
    high_paying_cat_df = high_paying_cat_df[high_paying_cat_df['monthly_salary'] < MAX_REASONABLE_SALARY]
    # Exclude 'é¢è­°' jobs recorded as 40000 to get a more accurate median salary
    high_paying_cat_df = high_paying_cat_df[~((high_paying_cat_df['salary_type'] == 'é¢è­°') & (high_paying_cat_df['monthly_salary'] == 40000))]
    top_paying_categories = high_paying_cat_df.groupby('category_name')['monthly_salary'].median().nlargest(10).reset_index()
    top_paying_categories.columns = ['category', 'median_salary']
    fig_top_cat = px.bar(
        top_paying_categories.sort_values('median_salary', ascending=True),
        x='median_salary',
        y='category',
        orientation='h',
        title="Top 10 é«˜è–ªè·ç¼ºåˆ†é¡",
        labels={'category': 'è·ç¼ºåˆ†é¡', 'median_salary': 'è–ªè³‡ä¸­ä½æ•¸ (å…ƒ)'},
        text='median_salary'
    )
    fig_top_cat.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_top_cat.update_layout(title_font_size=16, height=450)
    st.plotly_chart(fig_top_cat, use_container_width=True)

with c4:
    # Popular Cities Salary Range Comparison
    top_cities_for_salary = df_filtered['city'].value_counts().nlargest(5).index
    city_salary_df = df_filtered[df_filtered['city'].isin(top_cities_for_salary)].copy()
    city_salary_df = city_salary_df.dropna(subset=['monthly_salary'])
    city_salary_df = city_salary_df[city_salary_df['monthly_salary'] < MAX_REASONABLE_SALARY]
    # Exclude 'é¢è­°' jobs recorded as 40000 to get a more accurate salary range
    city_salary_df = city_salary_df[~((city_salary_df['salary_type'] == 'é¢è­°') & (city_salary_df['monthly_salary'] == 40000))]

    if not city_salary_df.empty:
        salary_quantiles = city_salary_df.groupby('city')['monthly_salary'].quantile([0.25, 0.5, 0.75]).unstack().reset_index()
        salary_quantiles.columns = ['city', 'ä½æ¨™ (25%)', 'ä¸­ä½æ•¸ (50%)', 'é«˜æ¨™ (75%)']
        salary_quantiles_melted = salary_quantiles.melt(
            id_vars='city', 
            var_name='è–ªè³‡æŒ‡æ¨™', 
            value_name='æœˆè–ª'
        )
        fig_city_salary_range = px.bar(
            salary_quantiles_melted,
            x='city',
            y='æœˆè–ª',
            color='è–ªè³‡æŒ‡æ¨™',
            barmode='group',
            title='ç†±é–€åŸå¸‚è–ªè³‡ç¯„åœæ¯”è¼ƒ (Top 5)',
            labels={'city': 'åŸå¸‚', 'æœˆè–ª': 'æœˆè–ª (å…ƒ)'},
            text='æœˆè–ª'
        )
        fig_city_salary_range.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
        fig_city_salary_range.update_layout(height=450)
        st.plotly_chart(fig_city_salary_range, use_container_width=True)
    else:
        st.write("ç„¡è¶³å¤ è³‡æ–™å¯é€²è¡ŒåŸå¸‚è–ªè³‡åˆ†æã€‚")


# --- åŸå¸‚è·ç¼ºåˆ†é¡ä½”æ¯” (å„ªåŒ–ç‰ˆ) ---
top_cities_for_dist = df_filtered['city'].value_counts().nlargest(5).index
city_category_df_for_dist = df_filtered[df_filtered['city'].isin(top_cities_for_dist)].copy()

# Merge categories for this chart specifically
city_category_df_for_dist['category_name'] = city_category_df_for_dist['category_name'].replace({'ç¶²ç«™é–‹ç™¼äººå“¡': 'å‰ç«¯å·¥ç¨‹å¸«'})
city_category_df_for_dist = city_category_df_for_dist[city_category_df_for_dist['category_name'] != 'æœªåˆ†é¡']
    
# --- Bug Fix: Calculate top categories based on the ENTIRE filtered dataset ---
# This ensures major roles like 'é›²ç«¯å·¥ç¨‹å¸«' are not missed
top_9_categories_overall = df_filtered['category_name'].value_counts().nlargest(9).index

# Group less frequent categories into 'å…¶ä»–'
city_category_df_for_dist['display_category'] = city_category_df_for_dist['category_name'].apply(
    lambda x: x if x in top_9_categories_overall else 'å…¶ä»–'
)

city_category_summary = city_category_df_for_dist.groupby(['city', 'display_category']).size().reset_index(name='count')

# Calculate percentage
city_sums = city_category_summary.groupby('city')['count'].transform('sum')
city_category_summary['percentage'] = (100 * city_category_summary['count'] / city_sums).round(1)

fig_city_category = px.bar(
    city_category_summary,
    x='city',
    y='percentage',
    color='display_category',
    title='ç†±é–€åŸå¸‚è·ç¼ºåˆ†é¡ä½”æ¯” (Top 5 åŸå¸‚, Top 9 åˆ†é¡)',
    labels={'city': 'åŸå¸‚', 'percentage': 'è·ç¼ºä½”æ¯” (%)', 'display_category': 'è·ç¼ºåˆ†é¡'},
    barmode='stack'
)
st.plotly_chart(fig_city_category, use_container_width=True)


# 1. Merge 'ç¶²ç«™é–‹ç™¼äººå“¡' into 'å‰ç«¯å·¥ç¨‹å¸«'
category_dist_df = df_filtered.copy()
category_dist_df['category_name'] = category_dist_df['category_name'].replace({'ç¶²ç«™é–‹ç™¼äººå“¡': 'å‰ç«¯å·¥ç¨‹å¸«'})
    
# 2. Filter out 'æœªåˆ†é¡'
category_dist_df = category_dist_df[category_dist_df['category_name'] != 'æœªåˆ†é¡']
    
# 3. Get top 20 categories
top_20_dist = category_dist_df['category_name'].value_counts().nlargest(20).reset_index()
top_20_dist.columns = ['category', 'count']

fig_all_cat_dist = px.bar(
    top_20_dist.sort_values('count', ascending=True),
    x='count',
    y='category',
    orientation='h',
    title='å…¨å¸‚å ´è·ç¼ºåˆ†é¡ä½”æ¯” (Top 20)',
    labels={'category': 'è·ç¼ºåˆ†é¡', 'count': 'è·ç¼ºæ•¸'},
    text='count'
)
fig_all_cat_dist.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
fig_all_cat_dist.update_layout(height=600)
st.plotly_chart(fig_all_cat_dist, use_container_width=True)


# --- Skill Processing Definitions ---
skill_merge_map = {
    'html5': 'HTML', 'html': 'HTML',
    'go': 'Go', 'golang': 'Go',
    'restful': 'RESTful API', 'restfulapi': 'RESTful API',
    'node': 'Node.js', 'nodejs': 'Node.js',
    'css': 'CSS', 'css3': 'CSS',
    'cèªè¨€': 'C' # å°‡ 'Cèªè¨€' çµ±ä¸€å°æ‡‰åˆ° 'C'
}
excluded_skills = {
    'git', 'linux', 'agile', 'ci/cd', 'github', 'gitlab', 'jenkins', 
    'restful api', 'shell script', 'scrum',
    'c' # ç²¾æº–æ’é™¤å› é—œéµå­— 'C' é€ æˆçš„å™ªè²
}

def process_skills(skills_list):
    processed_skills = []
    for s in skills_list:
        s_stripped = s.strip()
        s_lower = s_stripped.lower()
        if s_lower:
            s_merged = skill_merge_map.get(s_lower, s_stripped)
            if s_merged.lower() not in excluded_skills:
                processed_skills.append(s_merged)
    return processed_skills


st.divider()

# --- Skill Analysis ---
st.subheader("ğŸ’¡ ç†±é–€è·å‹™æŠ€èƒ½è§£æ")

# Add a selectbox to filter by category
# Get all categories with a reasonable number of jobs (>= 5) to provide a complete list
all_cat_counts_for_skills = df_filtered['category_name'].dropna().value_counts()
available_categories_for_skills = all_cat_counts_for_skills[all_cat_counts_for_skills >= 5].index.tolist()

# Set 'å¾Œç«¯å·¥ç¨‹å¸«' as default if available
default_category = 'å¾Œç«¯å·¥ç¨‹å¸«'
default_category_index = available_categories_for_skills.index(default_category) if default_category in available_categories_for_skills else 0

selected_category = st.selectbox(
    "é¸æ“‡è·ç¼ºåˆ†é¡ä¾†æŸ¥çœ‹æŠ€èƒ½éœ€æ±‚",
    options=available_categories_for_skills,
    index=default_category_index
)

if selected_category:
    # Filter dataframe by the selected category
    category_df = df_filtered[df_filtered['category_name'] == selected_category]

    c3, c4 = st.columns(2)
    with c3:
        # --- Popular Skills Treemap ---
        skills_flat_raw = category_df["required_skills"].dropna().str.cat(sep=",").split(",")
        skills_flat = process_skills(skills_flat_raw)
        skill_counts = Counter(skills_flat)
        skill_df = pd.DataFrame(skill_counts.items(), columns=["skill", "count"]).sort_values(
            by="count", ascending=False
        ).nlargest(15, 'count')

        if not skill_df.empty:
            fig_skills_treemap = px.treemap(
                skill_df,
                path=[px.Constant(f"{selected_category} ç†±é–€æŠ€èƒ½"), 'skill'],
                values='count',
                title=f'<b>{selected_category}</b> ç†±é–€æŠ€èƒ½åˆ†ä½ˆ',
                color_continuous_scale='Blues'
            )
            fig_skills_treemap.update_traces(hovertemplate='<b>%{label}</b><br>è·ç¼ºæ•¸: %{value}<extra></extra>')
            fig_skills_treemap.update_layout(margin = dict(t=50, l=25, r=25, b=25))
            st.plotly_chart(fig_skills_treemap, use_container_width=True)
        else:
            st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ æŠ€èƒ½è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)

    with c4:
        # --- Skill Salary Analysis within Category ---
        skills_salary_df = category_df.dropna(subset=['required_skills', 'monthly_salary'])
        skills_salary_df = skills_salary_df[skills_salary_df['monthly_salary'] < MAX_REASONABLE_SALARY]
        skills_salary_df = skills_salary_df[skills_salary_df['monthly_salary'] > 0]
        
        skills_list = []
        if not skills_salary_df.empty:
            for index, row in skills_salary_df.iterrows():
                skills_raw = row['required_skills'].split(',')
                skills = process_skills(skills_raw)
                for skill in skills:
                    skills_list.append({'skill': skill, 'monthly_salary': row['monthly_salary']})
        
        if skills_list:
            skills_exploded_df = pd.DataFrame(skills_list)
            skill_analysis = skills_exploded_df.groupby('skill')['monthly_salary'].agg(['mean', 'count']).reset_index()
            skill_analysis = skill_analysis.rename(columns={'mean': 'avg_salary'})

            # å°‡å¹³å‡è–ªè³‡å››æ¨äº”å…¥è‡³æ•´æ•¸ï¼Œä»¥åˆ©é–±è®€
            skill_analysis['avg_salary'] = skill_analysis['avg_salary'].round(0).astype(int)

            # Get top skills from the treemap data to ensure consistency
            top_skills_in_category = skill_df['skill'].tolist()
            skill_analysis_top = skill_analysis[skill_analysis['skill'].isin(top_skills_in_category)]
            skill_analysis_top = skill_analysis_top.sort_values(by='avg_salary', ascending=True)

            if not skill_analysis_top.empty:
                fig_skill_salary = px.bar(
                    skill_analysis_top,
                    x='avg_salary',
                    y='skill',
                    orientation='h',
                    title=f'<b>{selected_category}</b> ç†±é–€æŠ€èƒ½å¹³å‡è–ªè³‡',
                    labels={'skill': 'æŠ€èƒ½', 'avg_salary': 'å¹³å‡æœˆè–ª'},
                    text='avg_salary'
                )
                fig_skill_salary.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
                st.plotly_chart(fig_skill_salary, use_container_width=True)
            else:
                st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ è–ªè³‡è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)
        else:
            st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ è–ªè³‡è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)


st.divider()
# --- Skill Reverse Lookup ---
st.subheader("ğŸ’¡ æŠ€èƒ½èˆ‡å°±æ¥­æ©Ÿæœƒè§£æ")
# Create a list of top skills for the selectbox
all_skills_flat_raw = df_filtered["required_skills"].dropna().str.cat(sep=",").split(",")
all_skills_flat = process_skills(all_skills_flat_raw)
all_skill_counts = Counter(all_skills_flat)
top_50_skills = [skill for skill, count in all_skill_counts.most_common(50)]

# Set 'Java' as default if available
skill_options = sorted(top_50_skills)
default_skill = 'Java'
default_skill_index = skill_options.index(default_skill) if default_skill in skill_options else 0

selected_skill_lookup = st.selectbox(
    "é¸æ“‡ä¸€å€‹æŠ€èƒ½ä¾†æŸ¥è©¢ç›¸é—œè·ç¼ºåˆ†é¡èˆ‡ç¯„ä¾‹",
    options=skill_options,
    index=default_skill_index
)

if selected_skill_lookup:
    # A more robust way to check for skill presence
    def skill_in_row(skill_list_str, target_skill):
        if pd.isna(skill_list_str):
            return False
        skills = [s.strip().lower() for s in skill_list_str.split(',')]
        return target_skill.lower() in skills

    skill_lookup_df = df_filtered[df_filtered['required_skills'].apply(lambda x: skill_in_row(x, selected_skill_lookup))].copy()

    if not skill_lookup_df.empty:
        s_col1, s_col2 = st.columns([1, 1])

        with s_col1:
            category_counts = skill_lookup_df['category_name'].dropna().value_counts().nlargest(10).reset_index()
            category_counts.columns = ['category', 'count']
            
            fig_skill_cat = px.bar(
                category_counts,
                x='count',
                y='category',
                orientation='h',
                title=f"'{selected_skill_lookup}' çš„ Top 10 è·ç¼ºåˆ†é¡",
                labels={'category': 'è·ç¼ºåˆ†é¡', 'count': 'è·ç¼ºæ•¸'}
            )
            fig_skill_cat.update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=16)
            st.plotly_chart(fig_skill_cat, use_container_width=True)

        with s_col2:
            st.markdown(f"##### æ¢ç´¢ '{selected_skill_lookup}' ç›¸é—œè·ç¼º")

            # --- Filters ---
            search_term = st.text_input(
                "æœå°‹è·ç¨±æˆ–å…¬å¸", 
                key=f"search_{selected_skill_lookup}"
            )
            
            available_cities = sorted(skill_lookup_df['city'].dropna().unique())
            selected_cities = st.multiselect(
                "ç¯©é¸åŸå¸‚", 
                options=available_cities, 
                key=f"city_{selected_skill_lookup}"
            )

            # --- Apply Filters ---
            filtered_jobs = skill_lookup_df.copy()
            if search_term:
                filtered_jobs = filtered_jobs[
                    filtered_jobs['job_title'].str.contains(search_term, case=False, na=False) |
                    filtered_jobs['company_name'].str.contains(search_term, case=False, na=False)
                ]
            if selected_cities:
                filtered_jobs = filtered_jobs[filtered_jobs['city'].isin(selected_cities)]

            # Sort by creation date
            filtered_jobs = filtered_jobs.sort_values('created_at', ascending=False)
            
            # --- Pagination Logic ---
            if st.session_state.current_skill != selected_skill_lookup:
                st.session_state.page_number = 0
                st.session_state.current_skill = selected_skill_lookup

            page_size = 5
            total_jobs = len(filtered_jobs)
            total_pages = (total_jobs // page_size) + (1 if total_jobs % page_size > 0 else 0)
            start_idx = st.session_state.page_number * page_size
            end_idx = min(start_idx + page_size, total_jobs)

            paginated_jobs = filtered_jobs.iloc[start_idx:end_idx]

            # --- Display Jobs ---
            st.markdown(f"æ‰¾åˆ° **{total_jobs}** ç­†è·ç¼º")
            if total_jobs == 0:
                st.info("ç„¡ç¬¦åˆæ¢ä»¶çš„è·ç¼ºã€‚")
            
            for _, row in paginated_jobs.iterrows():
                salary_display = f"{row['monthly_salary']:,.0f} å…ƒ" if pd.notna(row['monthly_salary']) else "é¢è­°"
                st.markdown(
                    f"""
                    <div style="border: 1px solid #333; border-radius: 5px; padding: 10px; margin-bottom: 10px;">
                        <a href="{row['job_url']}" target="_blank" style="text-decoration: none; color: #1E90FF; font-weight: bold;">{row['job_title']}</a>
                        <p style="margin: 5px 0;">
                            <span style="font-style: italic;">{row['company_name']} - {row['city']}</span> | 
                            <span style="font-weight: bold; color: #FF4B4B;">{salary_display}</span>
                        </p>
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
            
            # --- Pagination Controls ---
            if total_pages > 1:
                p_col1, p_col2, p_col3 = st.columns([2, 3, 2])
                with p_col1:
                    if st.session_state.page_number > 0:
                        if st.button("â¬…ï¸ ä¸Šä¸€é "):
                            st.session_state.page_number -= 1
                            st.rerun()

                with p_col2:
                    st.write(f"é æ•¸: {st.session_state.page_number + 1} / {total_pages}")

                with p_col3:
                    if st.session_state.page_number < total_pages - 1:
                        if st.button("ä¸‹ä¸€é  â¡ï¸"):
                            st.session_state.page_number += 1
                            st.rerun()
    else:
        st.write(f"æ‰¾ä¸åˆ°åŒ…å« '{selected_skill_lookup}' æŠ€èƒ½çš„è·ç¼ºã€‚")


st.divider()
st.subheader("åŸå¸‚è–ªè³‡åˆ†æ")

# --- åŸå¸‚èˆ‡åˆ†é¡è–ªè³‡æ¯”è¼ƒ ---
# Find all categories with a reasonable number of jobs (e.g., >= 5) to provide a complete list
all_cat_counts = df_filtered['category_name'].dropna().value_counts()
available_categories_for_comparison = all_cat_counts[all_cat_counts >= 5].index.tolist()


# Add filters for city and category
selected_cities_for_comparison = st.multiselect(
    "é¸æ“‡è¦æ¯”è¼ƒçš„åŸå¸‚",
    options=sorted([city for city in df_filtered['city'].unique() if pd.notna(city)]),
    default=['è‡ºåŒ—å¸‚', 'é«˜é›„å¸‚']
)

# Set default categories for comparison, ensuring they exist in the options
default_categories_to_select = ['å‰ç«¯å·¥ç¨‹å¸«', 'å¾Œç«¯å·¥ç¨‹å¸«', 'é›²ç«¯å·¥ç¨‹å¸«', 'è³‡æ–™å·¥ç¨‹å¸«']
default_categories = [cat for cat in default_categories_to_select if cat in available_categories_for_comparison]
# If none of the preferred defaults are available, fall back to the top one from the available list
if not default_categories and available_categories_for_comparison:
    default_categories = available_categories_for_comparison[:1]

selected_categories_for_comparison = st.multiselect(
    "é¸æ“‡è¦æ¯”è¼ƒçš„è·ç¼ºåˆ†é¡",
    options=available_categories_for_comparison,
    default=default_categories
)

if selected_cities_for_comparison and selected_categories_for_comparison:
    comparison_df = df_filtered[
        df_filtered['city'].isin(selected_cities_for_comparison) &
        df_filtered['category_name'].isin(selected_categories_for_comparison)
    ].copy()

    # Filter out unreasonable salaries
    comparison_df = comparison_df[comparison_df['monthly_salary'] < MAX_REASONABLE_SALARY]
    comparison_df = comparison_df.dropna(subset=['monthly_salary'])

    if not comparison_df.empty:
        # æ”¹ç‚ºè¨ˆç®—è–ªè³‡ä¸­ä½æ•¸ï¼Œä»¥æä¾›æ›´ç©©å¥ã€æ›´å…·ä»£è¡¨æ€§çš„æ¯”è¼ƒ
        comparison_median_salary = comparison_df.groupby(['city', 'category_name'])['monthly_salary'].median().round(0).reset_index()

        fig_comparison = px.bar(
            comparison_median_salary,
            x='category_name',
            y='monthly_salary',
            color='city',
            barmode='group',
            # title='åŸå¸‚èˆ‡åˆ†é¡è–ªè³‡æ¯”è¼ƒ',
            labels={'category_name': 'è·ç¼ºåˆ†é¡', 'monthly_salary': 'è–ªè³‡ä¸­ä½æ•¸ (å…ƒ)', 'city': 'åŸå¸‚'},
            text='monthly_salary'
        )
        fig_comparison.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
        fig_comparison.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_comparison, use_container_width=True)
    else:
        st.write("ç„¡è¶³å¤ è³‡æ–™å¯é€²è¡Œæ¯”è¼ƒåˆ†æã€‚")
else:
    st.write("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹åŸå¸‚å’Œä¸€å€‹è·ç¼ºåˆ†é¡é€²è¡Œæ¯”è¼ƒã€‚")
