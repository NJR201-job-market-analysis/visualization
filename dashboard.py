import streamlit as st
import pandas as pd
import plotly.express as px
from sqlalchemy import create_engine
from st_aggrid import AgGrid, GridOptionsBuilder
from dotenv import load_dotenv
import os
from collections import Counter
from datetime import datetime, timedelta

# --- Session State Initialization ---
if 'page_number' not in st.session_state:
    st.session_state.page_number = 0
if 'current_skill' not in st.session_state:
    st.session_state.current_skill = None


load_dotenv()


# --- å»ºç«‹è³‡æ–™åº«é€£ç·š ---
@st.cache_resource
def connect_db():
    user = os.getenv("MYSQL_ACCOUNT")
    password = os.getenv("MYSQL_PASSWORD")
    host = os.getenv("MYSQL_HOST")
    port = os.getenv("MYSQL_PORT")
    db = os.getenv("MYSQL_DATABASE")

    conn_str = f"mysql+pymysql://{user}:{password}@{host}:{port}/{db}"
    engine = create_engine(conn_str)
    return engine


# --- è¼‰å…¥è³‡æ–™ä¸¦é è™•ç† ---
@st.cache_data
def load_data(_engine):
    query = """
    WITH FirstCategory AS (
        SELECT
            jc.job_id,
            MIN(c.name) AS category_name
        FROM jobs_categories jc
        JOIN categories c ON jc.category_id = c.id
        GROUP BY jc.job_id
    )
    SELECT
        j.*,
        GROUP_CONCAT(s.name SEPARATOR ',') AS aggregated_skills,
        fc.category_name
    FROM
        jobs AS j
    LEFT JOIN
        jobs_skills AS js ON j.id = js.job_id
    LEFT JOIN
        skills AS s ON js.skill_id = s.id
    LEFT JOIN
        FirstCategory AS fc ON j.id = fc.job_id
    GROUP BY
        j.id
    """
    with _engine.connect() as connection:
        df = pd.read_sql(query, connection)

    df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce")

    # è–ªè³‡æ¨™æº–åŒ–
    def normalize_salary(row):
        salary_min = row["salary_min"]
        salary_type = row["salary_type"]
        if pd.isna(salary_min):
            return None
        if salary_type == "å¹´è–ª":
            return salary_min / 12
        elif salary_type == "æ—¥è–ª":
            return salary_min * 22
        elif salary_type == "æ™‚è–ª":
            return salary_min * 176
        return salary_min

    df["monthly_salary"] = df.apply(normalize_salary, axis=1)
    
    # ä½¿ç”¨ aggregated_skills è¨ˆç®—æŠ€èƒ½æ•¸é‡
    df["skills_count"] = (
        df["aggregated_skills"].fillna("").apply(lambda x: len(x.split(",")) if x else 0)
    )
    # ç‚ºäº†å¾ŒçºŒåœ–è¡¨ç›¸å®¹æ€§ï¼Œå¦‚æœ aggregated_skills å­˜åœ¨ï¼Œå°±ç”¨å®ƒè¦†è“‹èˆŠçš„ required_skills
    if "aggregated_skills" in df.columns:
        df["required_skills"] = df["aggregated_skills"]
        
    return df


# --- ä¸»ç¨‹å¼é‚è¼¯ ---
st.set_page_config(page_title="å°±æ¥­å¸‚å ´ Dashboard", layout="wide")
st.title("ğŸ“Š å°±æ¥­å¸‚å ´ç¸½è¦½")

engine = connect_db()
df = load_data(engine)

# --- Sidebar Filters ---
st.sidebar.header("ç¯©é¸å™¨")
selected_platform = st.sidebar.multiselect(
    "å¹³å°",
    options=df["platform"].unique(),
    default=df["platform"].unique(),
)
selected_city = st.sidebar.multiselect(
    "åŸå¸‚",
    options=df["city"].unique(),
    default=df["city"].unique(),
)
df_filtered = df[
    df["platform"].isin(selected_platform) & df["city"].isin(selected_city)
]

# Define a global constant for salary filtering
MAX_REASONABLE_SALARY = 200000


# --- KPI Cards ---
col1, col2, col3, col4 = st.columns(4)

# 1. Total Jobs
col1.metric("ğŸ“Œ è·ç¼ºç¸½æ•¸", f"{len(df_filtered):,}")

# 2. Recruiting Companies
num_companies = df_filtered['company_name'].nunique()
col2.metric("ğŸ¢ å¾µæ‰å…¬å¸æ•¸", f"{num_companies:,}")

# 3. Median Salary
salary_df_for_median = df_filtered.dropna(subset=['monthly_salary'])
salary_df_for_median = salary_df_for_median[salary_df_for_median['monthly_salary'] < MAX_REASONABLE_SALARY]
median_salary = salary_df_for_median['monthly_salary'].median() if not salary_df_for_median.empty else 0
col3.metric("ğŸ’µ è–ªè³‡ä¸­ä½æ•¸ (æœˆ)", f"{median_salary:,.0f} å…ƒ")

# 4. Median Experience Requirement
exp_df_for_median = df_filtered.copy()
exp_df_for_median['experience_min'] = pd.to_numeric(exp_df_for_median['experience_min'], errors='coerce')
exp_df_for_median = exp_df_for_median.dropna(subset=['experience_min'])
median_exp = exp_df_for_median['experience_min'].median() if not exp_df_for_median.empty else 0
col4.metric("ğŸ“ˆ ç¶“é©—è¦æ±‚ä¸­ä½æ•¸ (å¹´)", f"{median_exp:.1f} å¹´")


st.divider()

# --- Market Overview ---
st.subheader("ğŸ“Š å¸‚å ´ç¸½è¦½")

c1, c2 = st.columns(2)

with c1:
    # 1. Job count per platform
    platform_df = df_filtered["platform"].value_counts().reset_index()
    platform_df.columns = ["platform", "count"]
    fig_platform = px.bar(
        platform_df, 
        y="count", 
        x="platform", 
        title="å„å¹³å°è·ç¼ºæ•¸é‡",
        labels={'platform': 'å¹³å°', 'count': 'è·ç¼ºæ•¸'},
        text='count'
    )
    fig_platform.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_platform.update_layout(xaxis={'categoryorder':'total descending'})
    st.plotly_chart(fig_platform, use_container_width=True)

with c2:
    # 2. Job count per city (top 10)
    city_df = df_filtered["city"].dropna().value_counts().nlargest(10).reset_index()
    city_df.columns = ["city", "count"]
    fig_city = px.bar(
        city_df, 
        y="count", 
        x="city", 
        title="å„åŸå¸‚è·ç¼ºæ•¸é‡ (Top 10)",
        labels={'city': 'åŸå¸‚', 'count': 'è·ç¼ºæ•¸'},
        text='count'
    )
    fig_city.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_city.update_layout(xaxis={'categoryorder':'total descending'})
    st.plotly_chart(fig_city, use_container_width=True)

c3, c4 = st.columns(2)

with c3:
    # 3. Job heat (most frequent job categories)
    category_df = df_filtered['category_name'].dropna().value_counts().nlargest(10).reset_index()
    category_df.columns = ['category', 'count']
    fig_category_heat = px.bar(
        category_df,
        y='count',
        x='category',
        title='è·ç¼ºç†±åº¦ (Top 10 åˆ†é¡)',
        labels={'category': 'è·ç¼ºåˆ†é¡', 'count': 'è·ç¼ºæ•¸'},
        text='count'
    )
    fig_category_heat.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_category_heat.update_layout(xaxis={'categoryorder':'total descending'}, xaxis_tickangle=-45)
    st.plotly_chart(fig_category_heat, use_container_width=True)

with c4:
    # 4. Work experience requirement distribution
    def map_experience(exp):
        try:
            if pd.isna(exp):
                return 'ç„¡éœ€ç¶“é©— / ä¸æ‹˜'
            exp_num = int(exp)
            if exp_num <= 0:
                return 'ç„¡éœ€ç¶“é©— / ä¸æ‹˜'
            elif exp_num <= 3:
                return '1-3å¹´'
            elif exp_num <= 5:
                return '3-5å¹´'
            else:
                return '5å¹´ä»¥ä¸Š'
        except (ValueError, TypeError):
            return 'ç„¡éœ€ç¶“é©— / ä¸æ‹˜'

    exp_df = df_filtered.copy()
    exp_df['experience_group'] = exp_df['experience_min'].apply(map_experience)
    exp_dist = exp_df['experience_group'].value_counts().reset_index()
    exp_dist.columns = ['group', 'count']
    
    # Define a logical order for the chart
    order = ['ç„¡éœ€ç¶“é©— / ä¸æ‹˜', '1-3å¹´', '3-5å¹´', '5å¹´ä»¥ä¸Š']

    fig_exp_dist = px.bar(
        exp_dist,
        x='group',
        y='count',
        title='å·¥ä½œç¶“é©—è¦æ±‚åˆ†ä½ˆ',
        labels={'group': 'ç¶“é©—è¦æ±‚', 'count': 'è·ç¼ºæ•¸'},
        text='count',
        category_orders={'group': order}
    )
    fig_exp_dist.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    st.plotly_chart(fig_exp_dist, use_container_width=True)


# --- Skill Analysis ---
st.divider()
st.subheader("ğŸ§  æŠ€èƒ½åˆ†æ (ä¾è·ç¼ºåˆ†é¡)")

# Add a selectbox to filter by category
top_categories = df_filtered['category_name'].dropna().value_counts().nlargest(10).index.tolist()
selected_category = st.selectbox(
    "é¸æ“‡è·ç¼ºåˆ†é¡ä¾†æŸ¥çœ‹æŠ€èƒ½éœ€æ±‚",
    options=top_categories
)

if selected_category:
    # Filter dataframe by the selected category
    category_df = df_filtered[df_filtered['category_name'] == selected_category]

    c3, c4 = st.columns(2)
    with c3:
        # --- Popular Skills Treemap ---
        skills_flat = category_df["required_skills"].dropna().str.cat(sep=",").split(",")
        skill_counts = Counter([s.strip() for s in skills_flat if s.strip()])
        skill_df = pd.DataFrame(skill_counts.items(), columns=["skill", "count"]).sort_values(
            by="count", ascending=False
        ).nlargest(15, 'count')

        if not skill_df.empty:
            fig_skills_treemap = px.treemap(
                skill_df,
                path=[px.Constant(f"{selected_category} ç†±é–€æŠ€èƒ½"), 'skill'],
                values='count',
                title=f'<b>{selected_category}</b> ç†±é–€æŠ€èƒ½åˆ†ä½ˆ',
                color_continuous_scale='Blues'
            )
            fig_skills_treemap.update_traces(hovertemplate='<b>%{label}</b><br>è·ç¼ºæ•¸: %{value}<extra></extra>')
            fig_skills_treemap.update_layout(margin = dict(t=50, l=25, r=25, b=25))
            st.plotly_chart(fig_skills_treemap, use_container_width=True)
        else:
            st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ æŠ€èƒ½è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)

    with c4:
        # --- Skill Salary Analysis within Category ---
        skills_salary_df = category_df.dropna(subset=['required_skills', 'monthly_salary'])
        skills_salary_df = skills_salary_df[skills_salary_df['monthly_salary'] < MAX_REASONABLE_SALARY]
        skills_salary_df = skills_salary_df[skills_salary_df['monthly_salary'] > 0]
        
        skills_list = []
        if not skills_salary_df.empty:
            for index, row in skills_salary_df.iterrows():
                skills = [s.strip() for s in row['required_skills'].split(',')]
                for skill in skills:
                    skills_list.append({'skill': skill, 'monthly_salary': row['monthly_salary']})
        
        if skills_list:
            skills_exploded_df = pd.DataFrame(skills_list)
            skill_analysis = skills_exploded_df.groupby('skill')['monthly_salary'].agg(['mean', 'count']).reset_index()
            skill_analysis = skill_analysis.rename(columns={'mean': 'avg_salary'})

            # Get top skills from the treemap data to ensure consistency
            top_skills_in_category = skill_df['skill'].tolist()
            skill_analysis_top = skill_analysis[skill_analysis['skill'].isin(top_skills_in_category)]
            skill_analysis_top = skill_analysis_top.sort_values(by='avg_salary', ascending=True)

            if not skill_analysis_top.empty:
                fig_skill_salary = px.bar(
                    skill_analysis_top,
                    x='avg_salary',
                    y='skill',
                    orientation='h',
                    title=f'<b>{selected_category}</b> ç†±é–€æŠ€èƒ½å¹³å‡è–ªè³‡',
                    labels={'skill': 'æŠ€èƒ½', 'avg_salary': 'å¹³å‡æœˆè–ª'},
                    text='avg_salary'
                )
                fig_skill_salary.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
                st.plotly_chart(fig_skill_salary, use_container_width=True)
            else:
                st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ è–ªè³‡è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)
        else:
            st.write(f"åœ¨ <b>{selected_category}</b> åˆ†é¡ä¸­ç„¡è¶³å¤ è–ªè³‡è³‡æ–™å¯åˆ†æã€‚", unsafe_allow_html=True)

# --- Skill Reverse Lookup ---
st.subheader("ğŸ” æ¢ç´¢æŠ€èƒ½çš„è·å‹™æ‡‰ç”¨ (ä¾æŠ€èƒ½åæŸ¥)")
# Create a list of top skills for the selectbox
all_skills_flat = df_filtered["required_skills"].dropna().str.cat(sep=",").split(",")
all_skill_counts = Counter([s.strip() for s in all_skills_flat if s.strip()])
top_50_skills = [skill for skill, count in all_skill_counts.most_common(50)]

selected_skill_lookup = st.selectbox(
    "é¸æ“‡ä¸€å€‹æŠ€èƒ½ä¾†æŸ¥è©¢ç›¸é—œè·ç¼ºåˆ†é¡èˆ‡ç¯„ä¾‹",
    options=sorted(top_50_skills)
)

if selected_skill_lookup:
    # A more robust way to check for skill presence
    def skill_in_row(skill_list_str, target_skill):
        if pd.isna(skill_list_str):
            return False
        skills = [s.strip().lower() for s in skill_list_str.split(',')]
        return target_skill.lower() in skills

    skill_lookup_df = df_filtered[df_filtered['required_skills'].apply(lambda x: skill_in_row(x, selected_skill_lookup))].copy()

    if not skill_lookup_df.empty:
        s_col1, s_col2 = st.columns([1, 1])

        with s_col1:
            st.markdown(f"##### '{selected_skill_lookup}' ä¸»è¦æ‡‰ç”¨æ–¼ä»¥ä¸‹è·é¡")
            category_counts = skill_lookup_df['category_name'].dropna().value_counts().nlargest(10).reset_index()
            category_counts.columns = ['category', 'count']
            
            fig_skill_cat = px.bar(
                category_counts,
                x='count',
                y='category',
                orientation='h',
                title=f"'{selected_skill_lookup}' çš„ Top 10 è·ç¼ºåˆ†é¡",
                labels={'category': 'è·ç¼ºåˆ†é¡', 'count': 'è·ç¼ºæ•¸'}
            )
            fig_skill_cat.update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=16)
            st.plotly_chart(fig_skill_cat, use_container_width=True)

        with s_col2:
            st.markdown(f"##### æ¢ç´¢ '{selected_skill_lookup}' ç›¸é—œè·ç¼º")

            # --- Filters ---
            search_term = st.text_input(
                "æœå°‹è·ç¨±æˆ–å…¬å¸", 
                key=f"search_{selected_skill_lookup}"
            )
            
            available_cities = sorted(skill_lookup_df['city'].dropna().unique())
            selected_cities = st.multiselect(
                "ç¯©é¸åŸå¸‚", 
                options=available_cities, 
                key=f"city_{selected_skill_lookup}"
            )

            # --- Apply Filters ---
            filtered_jobs = skill_lookup_df.copy()
            if search_term:
                filtered_jobs = filtered_jobs[
                    filtered_jobs['job_title'].str.contains(search_term, case=False, na=False) |
                    filtered_jobs['company_name'].str.contains(search_term, case=False, na=False)
                ]
            if selected_cities:
                filtered_jobs = filtered_jobs[filtered_jobs['city'].isin(selected_cities)]

            # Sort by creation date
            filtered_jobs = filtered_jobs.sort_values('created_at', ascending=False)
            
            # --- Pagination Logic ---
            if st.session_state.current_skill != selected_skill_lookup:
                st.session_state.page_number = 0
                st.session_state.current_skill = selected_skill_lookup

            page_size = 5
            total_jobs = len(filtered_jobs)
            total_pages = (total_jobs // page_size) + (1 if total_jobs % page_size > 0 else 0)
            start_idx = st.session_state.page_number * page_size
            end_idx = min(start_idx + page_size, total_jobs)

            paginated_jobs = filtered_jobs.iloc[start_idx:end_idx]

            # --- Display Jobs ---
            st.markdown(f"æ‰¾åˆ° **{total_jobs}** ç­†è·ç¼º")
            if total_jobs == 0:
                st.info("ç„¡ç¬¦åˆæ¢ä»¶çš„è·ç¼ºã€‚")
            
            for _, row in paginated_jobs.iterrows():
                salary_display = f"{row['monthly_salary']:,.0f} å…ƒ" if pd.notna(row['monthly_salary']) else "é¢è­°"
                st.markdown(
                    f"""
                    <div style="border: 1px solid #333; border-radius: 5px; padding: 10px; margin-bottom: 10px;">
                        <a href="{row['job_url']}" target="_blank" style="text-decoration: none; color: #1E90FF; font-weight: bold;">{row['job_title']}</a>
                        <p style="margin: 5px 0;">
                            <span style="font-style: italic;">{row['company_name']} - {row['city']}</span> | 
                            <span style="font-weight: bold; color: #FF4B4B;">{salary_display}</span>
                        </p>
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
            
            # --- Pagination Controls ---
            if total_pages > 1:
                p_col1, p_col2, p_col3 = st.columns([2, 3, 2])
                with p_col1:
                    if st.session_state.page_number > 0:
                        if st.button("â¬…ï¸ ä¸Šä¸€é "):
                            st.session_state.page_number -= 1
                            st.rerun()

                with p_col2:
                    st.write(f"é æ•¸: {st.session_state.page_number + 1} / {total_pages}")

                with p_col3:
                    if st.session_state.page_number < total_pages - 1:
                        if st.button("ä¸‹ä¸€é  â¡ï¸"):
                            st.session_state.page_number += 1
                            st.rerun()
    else:
        st.write(f"æ‰¾ä¸åˆ°åŒ…å« '{selected_skill_lookup}' æŠ€èƒ½çš„è·ç¼ºã€‚")


st.divider()
st.subheader("ğŸ™ï¸ åˆ†é¡èˆ‡åŸå¸‚åˆ†æ")

# --- åŸå¸‚èˆ‡åˆ†é¡è–ªè³‡æ¯”è¼ƒ ---
# Find top 10 most common categories to populate the filter
top_10_common_categories = df_filtered['category_name'].dropna().value_counts().nlargest(10).index.tolist()

# Add filters for city and category
selected_cities_for_comparison = st.multiselect(
    "é¸æ“‡è¦æ¯”è¼ƒçš„åŸå¸‚",
    options=sorted([city for city in df_filtered['city'].unique() if pd.notna(city)]),
    default=df_filtered['city'].value_counts().nlargest(2).index.tolist() # Default to top 2 cities
)

selected_categories_for_comparison = st.multiselect(
    "é¸æ“‡è¦æ¯”è¼ƒçš„è·ç¼ºåˆ†é¡",
    options=top_10_common_categories,
    default=top_10_common_categories[:3] # Default to top 3 most common categories
)

if selected_cities_for_comparison and selected_categories_for_comparison:
    comparison_df = df_filtered[
        df_filtered['city'].isin(selected_cities_for_comparison) &
        df_filtered['category_name'].isin(selected_categories_for_comparison)
    ].copy()

    # Filter out unreasonable salaries
    comparison_df = comparison_df[comparison_df['monthly_salary'] < MAX_REASONABLE_SALARY]
    comparison_df = comparison_df.dropna(subset=['monthly_salary'])

    if not comparison_df.empty:
        # Calculate average salary
        comparison_avg_salary = comparison_df.groupby(['city', 'category_name'])['monthly_salary'].mean().round(0).reset_index()

        fig_comparison = px.bar(
            comparison_avg_salary,
            x='category_name',
            y='monthly_salary',
            color='city',
            barmode='group',
            title='åŸå¸‚èˆ‡åˆ†é¡è–ªè³‡æ¯”è¼ƒ',
            labels={'category_name': 'è·ç¼ºåˆ†é¡', 'monthly_salary': 'å¹³å‡æœˆè–ª', 'city': 'åŸå¸‚'},
            text='monthly_salary'
        )
        fig_comparison.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
        fig_comparison.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_comparison, use_container_width=True)
    else:
        st.write("ç„¡è¶³å¤ è³‡æ–™å¯é€²è¡Œæ¯”è¼ƒåˆ†æã€‚")
else:
    st.write("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹åŸå¸‚å’Œä¸€å€‹è·ç¼ºåˆ†é¡é€²è¡Œæ¯”è¼ƒã€‚")


# --- åŸå¸‚è·ç¼ºåˆ†é¡ ---
top_cities = df_filtered['city'].value_counts().nlargest(5).index
city_category_df = df_filtered[df_filtered['city'].isin(top_cities)]
city_category_summary = city_category_df.groupby(['city', 'category_name']).size().reset_index(name='count')

# Calculate percentage
city_sums = city_category_summary.groupby('city')['count'].transform('sum')
city_category_summary['percentage'] = 100 * city_category_summary['count'] / city_sums

fig_city_category = px.bar(
    city_category_summary,
    x='city',
    y='percentage',
    color='category_name',
    title='ç†±é–€åŸå¸‚è·ç¼ºåˆ†é¡ä½”æ¯”',
    labels={'city': 'åŸå¸‚', 'percentage': 'è·ç¼ºä½”æ¯” (%)', 'category_name': 'è·ç¼ºåˆ†é¡'},
    barmode='stack'
)
st.plotly_chart(fig_city_category, use_container_width=True)

# --- åŸå¸‚è–ªè³‡ç¯„åœæ¯”è¼ƒ ---
st.markdown("##### ğŸ™ï¸ ç†±é–€åŸå¸‚è–ªè³‡ç¯„åœæ¯”è¼ƒ")
city_salary_df = df_filtered[df_filtered['city'].isin(top_cities)].copy()
city_salary_df = city_salary_df.dropna(subset=['monthly_salary'])
city_salary_df = city_salary_df[city_salary_df['monthly_salary'] < MAX_REASONABLE_SALARY]

if not city_salary_df.empty:
    # Calculate quantiles
    salary_quantiles = city_salary_df.groupby('city')['monthly_salary'].quantile([0.25, 0.5, 0.75]).unstack().reset_index()
    salary_quantiles.columns = ['city', 'ä½æ¨™ (25%)', 'ä¸­ä½æ•¸ (50%)', 'é«˜æ¨™ (75%)']
    
    # Melt the dataframe for plotting
    salary_quantiles_melted = salary_quantiles.melt(
        id_vars='city', 
        var_name='è–ªè³‡æŒ‡æ¨™', 
        value_name='æœˆè–ª'
    )

    fig_city_salary_range = px.bar(
        salary_quantiles_melted,
        x='city',
        y='æœˆè–ª',
        color='è–ªè³‡æŒ‡æ¨™',
        barmode='group',
        title='ç†±é–€åŸå¸‚è–ªè³‡ç¯„åœæ¯”è¼ƒ',
        labels={'city': 'åŸå¸‚', 'æœˆè–ª': 'æœˆè–ª (å…ƒ)'},
        text='æœˆè–ª'
    )
    fig_city_salary_range.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    st.plotly_chart(fig_city_salary_range, use_container_width=True)
else:
    st.write("ç„¡è¶³å¤ è³‡æ–™å¯é€²è¡ŒåŸå¸‚è–ªè³‡åˆ†æã€‚")


st.divider()
st.subheader("ğŸ“Š å¸‚å ´æ’è¡Œæ¦œ")

# --- First Row of Leaderboards ---
insight_col1, insight_col2 = st.columns(2)

with insight_col1:
    # 1. Top Hirers
    st.markdown("##### ğŸ¢ ä¸»è¦æ‹›è˜å…¬å¸")
    top_hirers = df_filtered['company_name'].dropna().value_counts().nlargest(10).reset_index()
    top_hirers.columns = ['company', 'count']
    fig_hirers = px.bar(
        top_hirers,
        x='count',
        y='company',
        orientation='h',
        title="Top 10 æ‹›è˜å…¬å¸",
        labels={'company': 'å…¬å¸', 'count': 'è·ç¼ºæ•¸'}
    )
    fig_hirers.update_layout(yaxis={'categoryorder':'total ascending'}, title_font_size=16, height=400)
    st.plotly_chart(fig_hirers, use_container_width=True)

with insight_col2:
    # 2. Top Paying Categories
    st.markdown("##### ğŸ’µ é«˜è–ªè·ç¼ºåˆ†é¡æ’è¡Œ")
    # Filter for categories with at least 5 job postings
    cat_counts = df_filtered['category_name'].value_counts()
    valid_categories = cat_counts[cat_counts >= 5].index
    
    high_paying_cat_df = df_filtered[df_filtered['category_name'].isin(valid_categories)].copy()
    high_paying_cat_df = high_paying_cat_df[high_paying_cat_df['monthly_salary'] < MAX_REASONABLE_SALARY]
    
    top_paying_categories = high_paying_cat_df.groupby('category_name')['monthly_salary'].median().nlargest(10).reset_index()
    top_paying_categories.columns = ['category', 'median_salary']

    fig_top_cat = px.bar(
        top_paying_categories.sort_values('median_salary', ascending=True),
        x='median_salary',
        y='category',
        orientation='h',
        title="Top 10 é«˜è–ªè·ç¼ºåˆ†é¡",
        labels={'category': 'è·ç¼ºåˆ†é¡', 'median_salary': 'è–ªè³‡ä¸­ä½æ•¸ (å…ƒ)'},
        text='median_salary'
    )
    fig_top_cat.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    fig_top_cat.update_layout(title_font_size=16, height=400)
    st.plotly_chart(fig_top_cat, use_container_width=True)

# --- Second Row for the last chart ---
# 3. Top Paying Companies
st.markdown("##### ğŸ’° é«˜è–ªå…¬å¸æ’è¡Œ")
# Filter for companies with at least 5 job postings
comp_counts = df_filtered['company_name'].value_counts()
valid_companies = comp_counts[comp_counts >= 5].index

high_paying_comp_df = df_filtered[df_filtered['company_name'].isin(valid_companies)].copy()
high_paying_comp_df = high_paying_comp_df[high_paying_comp_df['monthly_salary'] < MAX_REASONABLE_SALARY]

top_paying_companies = high_paying_comp_df.groupby('company_name')['monthly_salary'].median().nlargest(10).reset_index()
top_paying_companies.columns = ['company', 'median_salary']

fig_top_comp = px.bar(
    top_paying_companies.sort_values('median_salary', ascending=True),
    x='median_salary',
    y='company',
    orientation='h',
    title="Top 10 é«˜è–ªå…¬å¸",
    labels={'company': 'å…¬å¸', 'median_salary': 'è–ªè³‡ä¸­ä½æ•¸ (å…ƒ)'},
    text='median_salary'
)
fig_top_comp.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
fig_top_comp.update_layout(title_font_size=16, height=400)
st.plotly_chart(fig_top_comp, use_container_width=True)
